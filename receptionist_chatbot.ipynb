{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Path to the 'scraped' folder\n",
    "folder_path = 'catbotdata/'\n",
    "\n",
    "# Function to recursively extract text from JSON data\n",
    "def extract_text(data):\n",
    "    if isinstance(data, dict):\n",
    "        result = []\n",
    "        for key, value in data.items():\n",
    "            result.extend(extract_text(value))\n",
    "        return result\n",
    "    elif isinstance(data, list):\n",
    "        result = []\n",
    "        for item in data:\n",
    "            result.extend(extract_text(item))\n",
    "        return result\n",
    "    elif isinstance(data, str):\n",
    "        return [data]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load all JSON files from the 'scraped' folder\n",
    "def load_all_json_files(folder_path):\n",
    "    # List all files in the 'scraped' folder\n",
    "    json_files = [file for file in os.listdir(folder_path) if file.endswith('.json')]\n",
    "    # print(json_files)\n",
    "    \n",
    "    extracted_text = []\n",
    "    # Iterate over each JSON file\n",
    "    for json_file in json_files:\n",
    "        file_path = os.path.join(folder_path, json_file)\n",
    "        # Open and load the JSON file\n",
    "        with open(file_path, 'r') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                # print(f\"Loaded {json_file} successfully.\")\n",
    "                \n",
    "                # Extract text from the JSON data\n",
    "                extracted_text.extend(extract_text(data))\n",
    "                extracted_text.append('\\n')\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error loading {json_file}: {e}\")\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to load all JSON files and extract text\n",
    "extracted_text = load_all_json_files(folder_path)\n",
    "\n",
    "extracted_text='-'.join(extracted_text)\n",
    "\n",
    "# Return the collected data\n",
    "# print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('training_data.txt', 'a') as fp:\n",
    "#     fp.write(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating chunks of data\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "chunks=splitter.split_text(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "import pickle\n",
    "import glob \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import VectorDBQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amits\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\amits\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings=HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "store=FAISS.from_texts(chunks, embedding=embeddings, )\n",
    "faiss.write_index(store.index, 'docsind.index')\n",
    "store.index=None\n",
    "with open(r'faiss_store.pkl', 'wb') as fp:\n",
    "    pickle.dump(store, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=faiss.read_index(\"docsind.index\")\n",
    "with open(\"faiss_store.pkl\", \"rb\") as f:\n",
    "    store=pickle.load(f)\n",
    "\n",
    "store.index=index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='-Curriculum-Automobile SyllabusB.Tech. in Automobile Engg. Admission Year 20-21 (B.Tech. 23-24)B.Tech. in Automobile Engg. Admission Year 21-22 (T.Y. 23-24)B.Tech. in Automobile Engg. Admission Year 22-23 (S.Y. 23-24)B.Tech. in Automobile Engg. Admission Year 23-24 (F.Y. 23-24) NEP SchemeF.E. (REV- 2019 – C Scheme)S.E. (REV- 2019 – C Scheme)T.E. (REV- 2019 – C Scheme)S.E. to B.E. (Rev- 2016 – CBCGS Scheme)-B.Tech. in Automobile Engg. Admission Year 20-21 (B.Tech. 23-24)-https://www.pce.ac.in/wp-content/uploads/2023/12/1-B.Tech-in-Automobile-Engg-Admission-Year-20-21-B.Tech-23-24.pdf-B.Tech. in Automobile Engg. Admission Year 21-22 (T.Y. 23-24)-https://www.pce.ac.in/wp-content/uploads/2023/12/2-B.Tech-in-Automobile-Engg-Admission-Year-21-22-TY-23-24.pdf-B.Tech. in Automobile Engg. Admission Year 22-23 (S.Y. 23-24)-https://www.pce.ac.in/wp-content/uploads/2023/12/3-B.Tech-in-Automobile-Engg-Admission-Year-22-23-SY-23-24.pdf-B.Tech. in Automobile Engg. Admission Year 23-24 (F.Y. 23-24)'), Document(page_content='inculcate a professional and ethical attitude, good leadership qualities and commitment to social responsibilities in their thought process.Students will be encouraged to understand the importance of lifelong learning, working on contemporary global issues and to become a successful entrepreneur.Program Specific Outcomes (PSOs)Students should be able to generate and develop ideas that can result in self employment (eg. Start-ups) and create more jobs.Students should be updated with the latest trends in automobile engineering, beyond curriculum by way of doing internships and research projects.-Home-https://www.pce.ac.in/-Academics-https://www.pce.ac.in/academics/-Bachelors-https://www.pce.ac.in/academics/bachelors/-Automobile Engineering-https://www.pce.ac.in/academics/bachelors/automobile-engineering/curriculum/-Sem I - VIII-https://www.pce.ac.in/academics/bachelors/automobile-engineering/curriculum/-'), Document(page_content='for innovative teaching and evaluation techniques;-(c) Suggest panel of names to the Academic Council for appointment of examiners; and(d) Coordinate research, teaching, extension and other academic activities in the department/college.-Board of Studies for Automobile Engineering Department-Board of Studies for Automobile Engineering Department-tablepress-294-Dr. Divya Padmanabhan-Coordinator (Chairperson)-Prof. Amey Marathe-Teacher-Prof. Ameya Nijasure-Teacher-Dr. Basavraj Talikotti-Teacher-Dr. S. R. Kumbhar-Academic Council NomineeProfessor, RIT, Islampur, Sangli,Shivaji Univerisity, Kolhapur-Mr. Sanjay Nibhande-Academic Council NomineeChairman, SAE-Western Section / Automotive Research Association of India, Pune-Dr. Prasanna Nambiar-Vice Chancellor Nominee, PrincipalDon Bosco Institute of Technology, Kurla-Mr. Narayan Kulkarni-Placement Representative, Consultant / Ex Deputy General Manager, TOYO, Mumbai-Mr. Tejas Kamath-Alumnus NomineeTata Elxsi-Dr. K. C. Vora-Industry Expert'), Document(page_content='-Program Overview-Affiliated to-Duration-Academic Year-Intake-Theory Exam-Curriculum-University of Mumbai-4 years, Full Time-2 semesters each-60-University of Mumbai-Sem I - VIII-Home»Academics»Bachelors»Automobile Engineering»Program OverviewProgram OverviewB.Tech. in Automobile EngineeringAffiliated toDurationAcademic YearIntakeTheory ExamCurriculumUniversity of Mumbai4 years, Full Time2 semesters each60University of MumbaiSem I - VIIIResearch AreasThe Faculty of the Department of Automobile Engineering are experts in numerous disciplines and are involved in following research areas:Thermal EngineeringAdvanced ManufacturingStress AnalysisBiomaterialWelding TechnologyUndergraduate LabsEngineering MechanicsAutomobile EngineeringProduction ProcessCAD/FEAMaterial TechnologyMechanical Engg. MeasurementsHydraulic MachineryThermal EngineeringAutotronicsVehicle MaintananceProgram OverviewAutomobile Engineering, also known as Automotive Engineering, is the study of designing, operating and')]\n"
     ]
    }
   ],
   "source": [
    "print(store.similarity_search(\"syllabus of automobile\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(store.similarity_search(\"syllabus of automobile\"))\n",
    "\n",
    "# Your predefined template\n",
    "template = \"\"\"\n",
    "You are a chatbot assistant by Pillai College of Engineering that provides information about student services and the college.\n",
    "If you don't know the answer, just say \"sorry..!, I'm not sure about the answer. Please visit the website for further assistance.\" \n",
    "Don't try to make up an answer.\n",
    "\n",
    "HUMAN: {question}\n",
    "=========\n",
    "{summaries}\n",
    "=========\n",
    "CHATBOT:\n",
    "\"\"\"\n",
    "\n",
    "# Function to generate the prompt using the template, chat history, and retrieved documents\n",
    "def generate_prompt(question, retrieved_docs):\n",
    "    # Combine previous conversation (chat history)\n",
    "    # history_text = \"\\n\".join([f\"HUMAN: {item['question']}\\nCHATBOT: {item['answer']}\" for item in chat_history])\n",
    "    \n",
    "    # Combine the retrieved documents from vector store (if any)\n",
    "    doc_summaries = \"\\n\".join([f\"CONTENT: {doc.page_content}\" for doc in retrieved_docs])\n",
    "\n",
    "    \n",
    "    # Fill in the template with chat history, question, and document summaries\n",
    "    prompt = template.format(question=question, summaries=doc_summaries)\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query LLaMA with the generated prompt\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "def query_llama(prompt):\n",
    "    hf_token='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'\n",
    "    client = InferenceClient(\n",
    "        \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        token=hf_token,\n",
    ")\n",
    "    response = client.chat_completion(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=500,\n",
    "        stream=False  # You can use streaming if you prefer\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Main function to search vector store, generate prompt using the template, and query LLaMA\n",
    "def query_with_template_and_sources(question, vectorstore):\n",
    "    # global chat_history\n",
    "    # Retrieve relevant documents from vector store\n",
    "    docs = vectorstore.similarity_search(question)\n",
    "    \n",
    "    # Generate the prompt using the template, including chat history and document summaries\n",
    "    prompt = generate_prompt(question, docs)\n",
    "    \n",
    "    # Query LLaMA model with the generated prompt\n",
    "    answer = query_llama(prompt)\n",
    "    \n",
    "    # Add the current question and answer to chat history\n",
    "    # chat_history.append({\"question\": question, \"answer\": answer})\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN: principal of pillai?\n",
      "The Principal of Pillai College of Engineering is Dr. Sandeep M. Joshi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amits\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\inference\\_generated\\types\\base.py:139: FutureWarning: Accessing 'ChatCompletionOutput' values through dict is deprecated and will be removed from version '0.25'. Use dataclass attributes instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "question='principal of pillai?'\n",
    "print(query_with_template_and_sources(question, store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
